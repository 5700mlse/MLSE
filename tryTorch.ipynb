{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:49:08.148772Z",
     "start_time": "2019-11-13T06:49:07.109767Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:49:14.612463Z",
     "start_time": "2019-11-13T06:49:08.914622Z"
    }
   },
   "outputs": [],
   "source": [
    "import MLSE_Class as MLSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:49:15.504310Z",
     "start_time": "2019-11-13T06:49:15.452288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/differentSoftware/eclipse/eclipse_all_data.csv\n",
      "lens: 50\n",
      "start:2,end:43\n",
      "(997,)\n",
      "the data shape is (997, 40)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[0 0 0 ... 0 2 17]\n",
      " [0 0 0 ... 0 6 16]\n",
      " [2 0 0 ... 0 3 13]\n",
      " ...\n",
      " [6 1 1 ... 0 33 2062]\n",
      " [14 3 1 ... 0 10 79]\n",
      " [10 0 0 ... 0 7 61]] (698,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "X_train_eclipse,Y_train_bugs_eclipse,X_test_eclipse,Y_test_bugs_eclipse = MLSE.classification_binary(\"differentSoftware/eclipse/eclipse_all_data.csv\",\n",
    "                                                                     'numberOfBugsFoundUntil',\"wmc\",0,\n",
    "                                                                       \"bugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:50:06.192023Z",
     "start_time": "2019-11-13T06:50:06.149967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_resampled: [(False, 388), (True, 470)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_eclipse, Y_train_bugs_eclipse)\n",
    "print(f'Y_resampled: {sorted(Counter(y_resampled).items())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:50:12.125786Z",
     "start_time": "2019-11-13T06:50:12.119755Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, target_list):\n",
    "        self.file_list = file_list\n",
    "        self.target_list = target_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.file_list[index]\n",
    "        label = self.target_list[index]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:50:55.315997Z",
     "start_time": "2019-11-13T06:50:55.311996Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:09.580566Z",
     "start_time": "2019-11-13T06:52:09.576567Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_eclipse_Y = torch.from_numpy(np.array(X_resampled, dtype=np.float32))\n",
    "Y_train_bugs_eclipse_Y = torch.from_numpy(np.array(y_resampled, dtype=np.float32))\n",
    "trainset_Y = ImageDataset(X_train_eclipse_Y, Y_train_bugs_eclipse_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:12.097677Z",
     "start_time": "2019-11-13T06:52:12.082858Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_eclipse = torch.from_numpy(np.array(X_train_eclipse, dtype=np.float32))\n",
    "Y_train_bugs_eclipse = torch.from_numpy(np.array(Y_train_bugs_eclipse, dtype=np.float32))\n",
    "trainset = ImageDataset(X_train_eclipse, Y_train_bugs_eclipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:12.922192Z",
     "start_time": "2019-11-13T06:52:12.917189Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_eclipse = torch.from_numpy(np.array(X_test_eclipse, dtype=np.float32))\n",
    "Y_test_bugs_eclipse = torch.from_numpy(np.array(Y_test_bugs_eclipse, dtype=np.float32))\n",
    "testset = ImageDataset(X_test_eclipse, Y_test_bugs_eclipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:16.409918Z",
     "start_time": "2019-11-13T06:52:16.392305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset.target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T20:01:14.913314Z",
     "start_time": "2019-11-06T20:01:14.909291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_eclipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:26.071784Z",
     "start_time": "2019-11-13T06:52:25.478551Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "from IPython.display import Image\n",
    "from torch.utils import data as Data\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:43.185910Z",
     "start_time": "2019-11-13T06:52:43.181912Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainset, batch_size=64, shuffle=True, drop_last=False)\n",
    "train_dataloader_Y = DataLoader(trainset_Y, batch_size=64, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:45.491137Z",
     "start_time": "2019-11-13T06:52:45.486135Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(testset, batch_size=64, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:46.385555Z",
     "start_time": "2019-11-13T06:52:46.379558Z"
    }
   },
   "outputs": [],
   "source": [
    "class Simple_MLP(nn.Module):\n",
    "    def __init__(self, size_list):\n",
    "        super(Simple_MLP, self).__init__()\n",
    "        layers = []\n",
    "        self.size_list = size_list\n",
    "        for i in range(len(size_list) - 2):\n",
    "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
    "            layers.append(nn.BatchNorm1d(num_features = size_list[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "#             layers.append(nn.Dropout(0.2))\n",
    "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:48.371988Z",
     "start_time": "2019-11-13T06:52:48.342815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Simple_MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=80, bias=True)\n",
      "    (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=80, out_features=160, bias=True)\n",
      "    (4): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=160, out_features=16, bias=True)\n",
      "    (7): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=16, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "\n",
    "model = Simple_MLP([40,80,160, 16, 2])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:52:50.580590Z",
     "start_time": "2019-11-13T06:52:50.574558Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    scheduler.step()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device).float()\n",
    "        target = target.to(device).long() # all data & model on same device\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:59:03.951334Z",
     "start_time": "2019-11-13T06:59:03.947333Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:59:04.427879Z",
     "start_time": "2019-11-13T06:59:04.416918Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        recall = []\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).long()\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "            recall.append(recall_score(target, predicted))\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        print('Testing Recall: ', np.mean(recall)*100, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T06:59:05.281096Z",
     "start_time": "2019-11-13T06:59:05.269091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Simple_MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=80, bias=True)\n",
      "    (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=80, out_features=160, bias=True)\n",
      "    (4): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=160, out_features=160, bias=True)\n",
      "    (7): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=160, out_features=640, bias=True)\n",
      "    (10): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=640, out_features=20, bias=True)\n",
      "    (13): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (16): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "\n",
    "model = Simple_MLP([40,80,160,160,640,20,10, 2])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T07:05:52.266467Z",
     "start_time": "2019-11-13T07:05:43.778779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.7245642651211132 Time:  0.22744512557983398 s\n",
      "Testing Loss:  0.8759328961372376\n",
      "Testing Accuracy:  48.49498327759198 %\n",
      "Testing Recall:  89.0842490842491 %\n",
      "====================\n",
      "Training Loss:  0.47149265625260095 Time:  0.3040003776550293 s\n",
      "Testing Loss:  0.5800063490867615\n",
      "Testing Accuracy:  76.92307692307693 %\n",
      "Testing Recall:  52.761904761904766 %\n",
      "====================\n",
      "Training Loss:  0.4361747584559701 Time:  0.32303738594055176 s\n",
      "Testing Loss:  0.4899646699428558\n",
      "Testing Accuracy:  80.2675585284281 %\n",
      "Testing Recall:  31.382539029597854 %\n",
      "====================\n",
      "Training Loss:  0.42177595604549756 Time:  0.3685920238494873 s\n",
      "Testing Loss:  0.4423814594745636\n",
      "Testing Accuracy:  80.93645484949833 %\n",
      "Testing Recall:  29.00754147812971 %\n",
      "====================\n",
      "Training Loss:  0.4371494027701291 Time:  0.34351491928100586 s\n",
      "Testing Loss:  0.44339950680732726\n",
      "Testing Accuracy:  80.93645484949833 %\n",
      "Testing Recall:  33.62895927601811 %\n",
      "====================\n",
      "Training Loss:  0.38474084301428363 Time:  0.3500382900238037 s\n",
      "Testing Loss:  0.4400504469871521\n",
      "Testing Accuracy:  82.6086956521739 %\n",
      "Testing Recall:  39.0 %\n",
      "====================\n",
      "Training Loss:  0.38010243665088306 Time:  0.3425583839416504 s\n",
      "Testing Loss:  0.44444153308868406\n",
      "Testing Accuracy:  82.2742474916388 %\n",
      "Testing Recall:  47.909090909090914 %\n",
      "====================\n",
      "Training Loss:  0.4033793129704215 Time:  0.341001033782959 s\n",
      "Testing Loss:  0.4393831491470337\n",
      "Testing Accuracy:  81.93979933110369 %\n",
      "Testing Recall:  50.343434343434346 %\n",
      "====================\n",
      "Training Loss:  0.33742173693396826 Time:  0.417996883392334 s\n",
      "Testing Loss:  0.4313072979450226\n",
      "Testing Accuracy:  83.61204013377926 %\n",
      "Testing Recall:  63.57321110262287 %\n",
      "====================\n",
      "Training Loss:  0.3571234806017442 Time:  0.31003475189208984 s\n",
      "Testing Loss:  0.46091132760047915\n",
      "Testing Accuracy:  82.2742474916388 %\n",
      "Testing Recall:  61.031746031746025 %\n",
      "====================\n",
      "Training Loss:  0.35743213241750543 Time:  0.4961376190185547 s\n",
      "Testing Loss:  0.44368637204170225\n",
      "Testing Accuracy:  82.94314381270902 %\n",
      "Testing Recall:  60.14102564102565 %\n",
      "====================\n",
      "Training Loss:  0.3674251233989542 Time:  0.32103800773620605 s\n",
      "Testing Loss:  0.45707386136054995\n",
      "Testing Accuracy:  82.6086956521739 %\n",
      "Testing Recall:  49.524475524475534 %\n",
      "====================\n",
      "Training Loss:  0.3549409806728363 Time:  0.3430016040802002 s\n",
      "Testing Loss:  0.4511575222015381\n",
      "Testing Accuracy:  82.2742474916388 %\n",
      "Testing Recall:  54.67614738202974 %\n",
      "====================\n",
      "Training Loss:  0.3313331820748069 Time:  0.35001325607299805 s\n",
      "Testing Loss:  0.4711536765098572\n",
      "Testing Accuracy:  80.93645484949833 %\n",
      "Testing Recall:  56.65567765567765 %\n",
      "====================\n",
      "Training Loss:  0.3339074443687092 Time:  0.3409881591796875 s\n",
      "Testing Loss:  0.44944732785224917\n",
      "Testing Accuracy:  80.93645484949833 %\n",
      "Testing Recall:  45.76470588235295 %\n",
      "====================\n",
      "Training Loss:  0.31295312670144165 Time:  0.4159986972808838 s\n",
      "Testing Loss:  0.458465176820755\n",
      "Testing Accuracy:  81.27090301003345 %\n",
      "Testing Recall:  52.33333333333334 %\n",
      "====================\n",
      "Training Loss:  0.3213773342696103 Time:  0.37099695205688477 s\n",
      "Testing Loss:  0.4728566467761993\n",
      "Testing Accuracy:  82.2742474916388 %\n",
      "Testing Recall:  56.79370629370629 %\n",
      "====================\n",
      "Training Loss:  0.3019592084667899 Time:  0.354001522064209 s\n",
      "Testing Loss:  0.4837961316108704\n",
      "Testing Accuracy:  81.93979933110369 %\n",
      "Testing Recall:  54.61538461538462 %\n",
      "====================\n",
      "Training Loss:  0.31263314187526703 Time:  0.32399964332580566 s\n",
      "Testing Loss:  0.47636242508888244\n",
      "Testing Accuracy:  81.60535117056857 %\n",
      "Testing Recall:  52.09803921568628 %\n",
      "====================\n",
      "Training Loss:  0.3001892322843725 Time:  0.3339998722076416 s\n",
      "Testing Loss:  0.4864153742790222\n",
      "Testing Accuracy:  80.60200668896321 %\n",
      "Testing Recall:  61.97802197802198 %\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "import time\n",
    "for i in range(n_epochs):\n",
    "    train_loss = train_epoch(model,train_dataloader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_dataloader, criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-13T07:08:20.095037Z",
     "start_time": "2019-11-13T07:08:10.806629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.1277914590069226 Time:  0.24417448043823242 s\n",
      "Testing Loss:  0.7860221028327942\n",
      "Testing Accuracy:  66.22073578595318 %\n",
      "Testing Recall:  80.67032967032966 %\n",
      "====================\n",
      "Training Loss:  0.12145556030528885 Time:  0.3705925941467285 s\n",
      "Testing Loss:  0.7429047703742981\n",
      "Testing Accuracy:  69.23076923076923 %\n",
      "Testing Recall:  76.6307418072124 %\n",
      "====================\n",
      "Training Loss:  0.1712374304022108 Time:  0.3915591239929199 s\n",
      "Testing Loss:  0.6885405063629151\n",
      "Testing Accuracy:  71.23745819397993 %\n",
      "Testing Recall:  76.98368298368298 %\n",
      "====================\n",
      "Training Loss:  0.13311656404818809 Time:  0.4265122413635254 s\n",
      "Testing Loss:  0.9154417514801025\n",
      "Testing Accuracy:  58.19397993311036 %\n",
      "Testing Recall:  81.33433233433234 %\n",
      "====================\n",
      "Training Loss:  0.10788762090461594 Time:  0.38900279998779297 s\n",
      "Testing Loss:  0.7549282550811768\n",
      "Testing Accuracy:  67.89297658862876 %\n",
      "Testing Recall:  81.13347763347763 %\n",
      "====================\n",
      "Training Loss:  0.11785744662795748 Time:  0.44199490547180176 s\n",
      "Testing Loss:  0.7777569770812989\n",
      "Testing Accuracy:  67.89297658862876 %\n",
      "Testing Recall:  80.26190476190476 %\n",
      "====================\n",
      "Training Loss:  0.1224789172410965 Time:  0.44355130195617676 s\n",
      "Testing Loss:  0.7840960383415222\n",
      "Testing Accuracy:  65.88628762541806 %\n",
      "Testing Recall:  83.33333333333334 %\n",
      "====================\n",
      "Training Loss:  0.1141291798225471 Time:  0.36099934577941895 s\n",
      "Testing Loss:  0.8545945882797241\n",
      "Testing Accuracy:  63.54515050167224 %\n",
      "Testing Recall:  83.87825624667731 %\n",
      "====================\n",
      "Training Loss:  0.12195632766400065 Time:  0.3660008907318115 s\n",
      "Testing Loss:  0.6718666791915894\n",
      "Testing Accuracy:  74.24749163879598 %\n",
      "Testing Recall:  78.54545454545455 %\n",
      "====================\n",
      "Training Loss:  0.11516730966312545 Time:  0.3500344753265381 s\n",
      "Testing Loss:  0.7534296393394471\n",
      "Testing Accuracy:  70.5685618729097 %\n",
      "Testing Recall:  79.10589410589411 %\n",
      "====================\n",
      "Training Loss:  0.12675175815820694 Time:  0.42600202560424805 s\n",
      "Testing Loss:  0.7194665193557739\n",
      "Testing Accuracy:  71.90635451505017 %\n",
      "Testing Recall:  77.99253034547152 %\n",
      "====================\n",
      "Training Loss:  0.13403352509651864 Time:  0.4237048625946045 s\n",
      "Testing Loss:  0.7678649067878723\n",
      "Testing Accuracy:  68.56187290969899 %\n",
      "Testing Recall:  78.73809523809523 %\n",
      "====================\n",
      "Training Loss:  0.1252781307058675 Time:  0.4035186767578125 s\n",
      "Testing Loss:  0.664600670337677\n",
      "Testing Accuracy:  74.24749163879598 %\n",
      "Testing Recall:  75.86589880707528 %\n",
      "====================\n",
      "Training Loss:  0.12140726670622826 Time:  0.3760035037994385 s\n",
      "Testing Loss:  0.8521681904792786\n",
      "Testing Accuracy:  61.53846153846154 %\n",
      "Testing Recall:  82.89377289377289 %\n",
      "====================\n",
      "Training Loss:  0.12621137207107885 Time:  0.39308953285217285 s\n",
      "Testing Loss:  0.7698587894439697\n",
      "Testing Accuracy:  69.89966555183946 %\n",
      "Testing Recall:  83.46853146853147 %\n",
      "====================\n",
      "Training Loss:  0.10261117666959763 Time:  0.38753437995910645 s\n",
      "Testing Loss:  0.7988956689834594\n",
      "Testing Accuracy:  66.88963210702342 %\n",
      "Testing Recall:  83.66138161803796 %\n",
      "====================\n",
      "Training Loss:  0.10819507496697563 Time:  0.42452502250671387 s\n",
      "Testing Loss:  0.7364445805549622\n",
      "Testing Accuracy:  70.23411371237458 %\n",
      "Testing Recall:  76.53896430367018 %\n",
      "====================\n",
      "Training Loss:  0.11084052867123059 Time:  0.41050052642822266 s\n",
      "Testing Loss:  0.806367039680481\n",
      "Testing Accuracy:  66.88963210702342 %\n",
      "Testing Recall:  82.19838056680162 %\n",
      "====================\n",
      "Training Loss:  0.10714703000017575 Time:  0.41899657249450684 s\n",
      "Testing Loss:  0.7405444264411927\n",
      "Testing Accuracy:  70.90301003344482 %\n",
      "Testing Recall:  78.47727272727273 %\n",
      "====================\n",
      "Training Loss:  0.10935777000018529 Time:  0.38303542137145996 s\n",
      "Testing Loss:  0.8168414235115051\n",
      "Testing Accuracy:  63.87959866220736 %\n",
      "Testing Recall:  81.38095238095238 %\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "import time\n",
    "for i in range(n_epochs):\n",
    "    train_loss = train_epoch(model,train_dataloader_Y, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_dataloader, criterion)\n",
    "    Train_loss.append(train_loss)\n",
    "    Test_loss.append(test_loss)\n",
    "    Test_acc.append(test_acc)\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
