{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1: prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def predicted_bugNum_vs_true_bugNum(Y_test_predict,Y_test_bugs):\n",
    "    n = 0\n",
    "    bugrowcount = 0\n",
    "    for i in range(0,len(Y_test_predict)):\n",
    "        if(Y_test_bugs[i]!=False):\n",
    "            bugrowcount += 1\n",
    "            if(Y_test_predict[i]==Y_test_bugs[i]):\n",
    "                n=n+1\n",
    "#    print(n/bugrowcount,n,bugrowcount)\n",
    "    return n/bugrowcount,n\n",
    "\n",
    "def load_one_version_method_matrix(matrix_path):\n",
    "    print(matrix_path)\n",
    "    return pd.read_csv(matrix_path)\n",
    "\n",
    "def get_selected_rows(columncombation,X_data):\n",
    "    flag = False\n",
    "    for i in columncombation:\n",
    "        if(flag == False):\n",
    "            c = X_data[:,i].T\n",
    "            flag = True\n",
    "        else:\n",
    "            c = np.vstack((c,X_data[:,i].T))\n",
    "    X_train_selected = c.T \n",
    "    return X_train_selected\n",
    "\n",
    "def classification_binary(csvpath,startColumnName,\n",
    "                          endColumnName,isdefects,\n",
    "                         bugcolumnName,columncombation_j = None):\n",
    "\n",
    "    filePath = \"AlltheMatrix/\"\n",
    "\n",
    "    filePathNowusing = filePath + csvpath\n",
    "\n",
    "    changed_matrix = load_one_version_method_matrix(filePathNowusing)\n",
    "    print(f'lens: {len(changed_matrix.columns.values)}')\n",
    "    matrixlen = int(len(changed_matrix))\n",
    "    startindex = 0\n",
    "    endindex = 0\n",
    "    for i, column in enumerate(changed_matrix.columns.values):\n",
    "        if(column == startColumnName):\n",
    "            startindex = i\n",
    "        elif (column == endColumnName):\n",
    "            endindex = i\n",
    "    print(f'start:{startindex},end:{endindex}') \n",
    "    target = changed_matrix[bugcolumnName].values\n",
    "    data = changed_matrix.values[:,startindex+1:endindex]\n",
    "    print(target.shape)\n",
    "    print(f'the data shape is {data.shape}')\n",
    "\n",
    "    #shuffleIndex\n",
    "    import numpy as np\n",
    "    shuffle_index = np.random.permutation(matrixlen)\n",
    "    target, data = target[shuffle_index], data[shuffle_index]\n",
    "\n",
    "    print(type(data))\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    #split the train set and the test set\n",
    "    X_train = data[:round(0.7*matrixlen)]\n",
    "    X_test = data[round(0.7*matrixlen):]\n",
    "    Y_train = target[:round(0.7*matrixlen)]\n",
    "    Y_test = target[round(0.7*matrixlen):]\n",
    "    print(X_train,Y_train.shape)\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    #train a binary classifier\n",
    "    Y_train_bugs = (Y_train > isdefects)\n",
    "    Y_test_bugs = (Y_test > isdefects)\n",
    "\n",
    "    if(columncombation_j!=None):\n",
    "        print(\"####################################\")\n",
    "        X_train = get_selected_rows(columncombation_j,X_train)\n",
    "        X_test = get_selected_rows(columncombation_j,X_test)\n",
    "    return X_train,Y_train_bugs,X_test,Y_test_bugs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[16.0 155.0 13.037037037037035 ... 0.013626834381551364 0.0 0.0]\n",
      " [0.0 0.0 1.0 ... 0.0 0.017543859649122806 0.0]\n",
      " [40.0 419.0 7.633802816901407 ... 0.007802093244529021 0.0 0.0]\n",
      " ...\n",
      " [3.0 3.0 7.0 ... 0.0 0.0 0.0]\n",
      " [7.0 8.0 3.5 ... 0.014084507042253518 0.007042253521126761 0.0]\n",
      " [9.0 57.0 2.3181818181818183 ... 0.0026223776223776225 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                               \"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset is clearly imbalanced, and I am going to use the following 5 methods to deal with it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: five ways to deal with the imbalanced dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train_bugs:[(False, 6346), (True, 1069)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.metrics import recall_score  \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def get_all_scores(y_real, y_pre):\n",
    "    return accuracy_score(y_real, y_pre), recall_score(y_real, y_pre), precision_score(y_real, y_pre), f1_score(y_real, y_pre)\n",
    "\n",
    "def append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,dataset):\n",
    "    accuracy_score_list.append(dataset[0])\n",
    "    recall_score_list.append(dataset[1])\n",
    "    precision_score_list.append(dataset[2])\n",
    "    f1_score_list.append(dataset[3])\n",
    "    \n",
    "def print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list):\n",
    "    print(f'The train  accuracy score is {np.mean(accuracy_score_list)}')\n",
    "    print(f'The train recall score is {np.mean(recall_score_list)}')\n",
    "    print(f'The train precision score is {np.mean(precision_score_list)}')\n",
    "    print(f'The train f1 score is {np.mean(f1_score_list)}')\n",
    "\n",
    "def print_all_test_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list):\n",
    "    print(f'The test accuracy score is {np.mean(accuracy_score_list)}')\n",
    "    print(f'The test recall score is {np.mean(recall_score_list)}')\n",
    "    print(f'The test precision score is {np.mean(precision_score_list)}')\n",
    "    print(f'The test f1 score is {np.mean(f1_score_list)}')\n",
    "\n",
    "# def init_the_list(accuracy_score_list = accuracy_score_list,recall_score_list = recall_score_list,\n",
    "#                   precision_score_list = precision_score_list,f1_score_list = f1_score_list,\n",
    "#                  accuracy_score_list2 = accuracy_score_list2,recall_score_list2 = recall_score_list2,\n",
    "#                   precision_score_list2 = precision_score_list2,f1_score_list2 = f1_score_list2):\n",
    "#     print(\"in\")\n",
    "#     print(len(accuracy_score_list))\n",
    "#     for i in range(len(accuracy_score_list)):\n",
    "#         accuracy_score_list.pop()\n",
    "#         recall_score_list.pop()\n",
    "#         precision_score_list.pop()\n",
    "#         f1_score_list.pop()\n",
    "#     print(f'list:{len(accuracy_score_list)}')\n",
    "#     for i in range(len(accuracy_score_list2)):\n",
    "#         accuracy_score_list2.pop()\n",
    "#         recall_score_list2.pop()\n",
    "#         precision_score_list2.pop()\n",
    "#         f1_score_list2.pop()\n",
    "#     print(f'list2:{len(accuracy_score_list2)}')\n",
    "    \n",
    "    \n",
    "accuracy_score_list = []\n",
    "recall_score_list = []\n",
    "precision_score_list = []\n",
    "f1_score_list = []\n",
    "accuracy_score_list2 = []\n",
    "recall_score_list2 = []\n",
    "precision_score_list2 = []\n",
    "f1_score_list2 = []\n",
    "print(f'Y_train_bugs:{sorted(Counter(Y_train_bugs).items())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.1: trying different algorithms\n",
    "# K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.8414096916299559\n",
      "The test recall score is 0.2817204301075269\n",
      "The test precision score is 0.43521594684385384\n",
      "The test f1 score is 0.34203655352480417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def KNN(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    for i in range(1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=3,weights = 'distance')\n",
    "        knn.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = knn.predict(X_train)\n",
    "        Y_test_predict = knn.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    #print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "KNN(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.8370044052863437\n",
      "The test recall score is 0.3032258064516129\n",
      "The test precision score is 0.4208955223880597\n",
      "The test f1 score is 0.3525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def NaivceBayes(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    for i in range(10):\n",
    "        NB =  GaussianNB()\n",
    "        NB.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = NB.predict(X_train)\n",
    "        Y_test_predict = NB.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    #print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "NaivceBayes(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:80\n",
      "(10593,)\n",
      "the data shape is (10593, 73)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[3.0 3.0 1.5 ... 51 4 4]\n",
      " [11.0 28.0 7.0 ... 258 14 8]\n",
      " [5.0 18.0 3.333333333333333 ... 148 24 5]\n",
      " ...\n",
      " [3.0 4.0 4.333333333333333 ... 45 7 2]\n",
      " [8.0 16.0 7.375 ... 149 27 14]\n",
      " [0.0 0.0 0.0 ... 9 0 0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.76431718061674\n",
      "The test recall score is 0.6420581655480985\n",
      "The test precision score is 0.3276255707762557\n",
      "The test f1 score is 0.43386243386243384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"StringLiteral\",0,\n",
    "                               \"post\")\n",
    "def logisticRegression(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    for i in range(5):\n",
    "        LR_clf = LogisticRegression(solver='liblinear',max_iter=1000,class_weight='balanced')\n",
    "        LR_clf.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = LR_clf.predict(X_train)\n",
    "        Y_test_predict = LR_clf.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    #print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "logisticRegression(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[2.0 10.0 1.0 ... 0.003003003003003003 0.003003003003003003\n",
      "  0.015015015015015015]\n",
      " [6.0 10.0 9.25 ... 0.0 0.0 0.0]\n",
      " [18.0 35.0 6.666666666666668 ... 0.0046801872074883 0.0015600624024961\n",
      "  0.0]\n",
      " ...\n",
      " [1.0 2.0 1.6 ... 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.8055380742605414\n",
      "The test recall score is 0.3340380549682875\n",
      "The test precision score is 0.34273318872017355\n",
      "The test f1 score is 0.33832976445396146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DecisionTree(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    print(len(accuracy_score_list2))\n",
    "    X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                                   \"post\")\n",
    "    for i in range(10):\n",
    "        DT = DecisionTreeClassifier(random_state=0,class_weight='balanced')\n",
    "        DT.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = DT.predict(X_train)\n",
    "        Y_test_predict = DT.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    #print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "DecisionTree(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[34.0 89.0 3.8333333333333335 ... 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.018867924528301886 0.0 0.0]\n",
      " [30.0 1035.0 11.525547445255475 ... 0.0016653236637120602\n",
      "  5.372011818426001e-05 0.0]\n",
      " ...\n",
      " [3.0 8.0 2.636363636363636 ... 0.003508771929824561 0.003508771929824561\n",
      "  0.0]\n",
      " [12.0 29.0 4.0 ... 0.0 0.002202643171806168 0.0]\n",
      " [18.0 19.0 14.333333333333336 ... 0.011389521640091115 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.8663624921334172\n",
      "The test recall score is 0.20144032921810698\n",
      "The test precision score is 0.7279270773995761\n",
      "The test f1 score is 0.31553369215812577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                                   \"post\")\n",
    "def RandomForest(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    for i in range(5):\n",
    "        RF = RandomForestClassifier(n_estimators = 200,criterion = 'entropy')\n",
    "        RF.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = RF.predict(X_train)\n",
    "        Y_test_predict = RF.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    #print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "RandomForest(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.8508495909376966\n",
      "The test recall score is 0.022727272727272728\n",
      "The test precision score is 0.9166666666666666\n",
      "The test f1 score is 0.04435483870967742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "def SVM_clf(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    for i in range(10):\n",
    "        svmclf = SVC(gamma='auto')\n",
    "        svmclf.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = svmclf.predict(X_train)\n",
    "        Y_test_predict = svmclf.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    #print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "SVM_clf(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[33.0 89.0 5.454545454545454 ... 0.002144388849177984\n",
      "  0.0014295925661186562 0.0]\n",
      " [9.0 22.0 8.2 ... 0.0024630541871921183 0.0024630541871921183 0.0]\n",
      " [1.0 2.0 1.5833333333333333 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [13.0 46.0 5.75 ... 0.00430416068866571 0.0014347202295552368 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [8.0 41.0 3.941176470588236 ... 0.0237741456166419 0.0014858841010401188\n",
      "  0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.8303335431088735\n",
      "The test recall score is 0.3696969696969697\n",
      "The test precision score is 0.4080198016726545\n",
      "The test f1 score is 0.3876870049462449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                                   \"post\")\n",
    "def neuralNetworks(X_train,Y_train_bugs,X_test,Y_test_bugs):\n",
    "    accuracy_score_list = []\n",
    "    recall_score_list = []\n",
    "    precision_score_list = []\n",
    "    f1_score_list = []\n",
    "    accuracy_score_list2 = []\n",
    "    recall_score_list2 = []\n",
    "    precision_score_list2 = []\n",
    "    f1_score_list2 = []\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    scaler.fit(X_test)\n",
    "    X_test= scaler.transform(X_test)\n",
    "    for i in range(5):\n",
    "        mclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100))\n",
    "        mclf.fit(X_train,Y_train_bugs)\n",
    "        Y_train_predict = mclf.predict(X_train)\n",
    "        Y_test_predict = mclf.predict(X_test)\n",
    "        train_set_result = get_all_scores(Y_train_bugs,Y_train_predict)\n",
    "        test_set_result = get_all_scores(Y_test_bugs,Y_test_predict)\n",
    "        append_socre_to_list(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list,train_set_result)\n",
    "        append_socre_to_list(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2,test_set_result)\n",
    "    # print_all_train_results(accuracy_score_list,recall_score_list,precision_score_list,f1_score_list)\n",
    "    print_all_test_results(accuracy_score_list2,recall_score_list2,precision_score_list2,f1_score_list2)\n",
    "neuralNetworks(X_train,Y_train_bugs,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2: oversample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "ros = RandomOverSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[13.0 71.0 5.933333333333334 ... 0.01426872770511296\n",
      "  0.0011890606420927464 0.0]\n",
      " [4.0 12.0 2.4166666666666665 ... 0.0 0.0 0.0]\n",
      " [5.0 9.0 6.75 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [21.0 128.0 11.882352941176471 ... 0.009993337774816787\n",
      "  0.0006662225183211193 0.0]\n",
      " [1.0 3.0 1.4444444444444444 ... 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Y_resampled: [(False, 6323), (True, 6323)]\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                               \"post\")\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, Y_train_bugs)\n",
    "print(f'Y_resampled: {sorted(Counter(y_resampled).items())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2 K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.751101321585903\n",
      "The test recall score is 0.5021008403361344\n",
      "The test precision score is 0.30138713745271123\n",
      "The test f1 score is 0.37667454688731283\n"
     ]
    }
   ],
   "source": [
    "KNN(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2 Naïve Bayes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.8351164254247955\n",
      "The test recall score is 0.2948453608247422\n",
      "The test precision score is 0.44000000000000006\n",
      "The test f1 score is 0.3530864197530864\n"
     ]
    }
   ],
   "source": [
    "NaivceBayes(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:80\n",
      "(10593,)\n",
      "the data shape is (10593, 73)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[0.0 0.0 0.0 ... 59 24 16]\n",
      " [3.0 6.0 5.5 ... 91 8 5]\n",
      " [23.0 51.0 9.428571428571429 ... 263 41 14]\n",
      " ...\n",
      " [33.0 77.0 34.666666666666664 ... 575 42 17]\n",
      " [0.0 0.0 1.0 ... 12 1 0]\n",
      " [8.0 22.0 7.6 ... 138 19 9]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.7567652611705477\n",
      "The test recall score is 0.6430205949656751\n",
      "The test precision score is 0.31291759465478836\n",
      "The test f1 score is 0.4209737827715355\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"StringLiteral\",0,\n",
    "                               \"post\")\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, Y_train_bugs)\n",
    "logisticRegression(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[15.0 39.0 5.25 ... 0.003322259136212625 0.0 0.0]\n",
      " [12.0 31.0 4.5 ... 0.0036630036630036634 0.0 0.0]\n",
      " [6.0 13.0 4.0 ... 0.012072434607645876 0.0 0.0]\n",
      " ...\n",
      " [1.0 3.0 1.0 ... 0.00641025641025641 0.01282051282051282 0.0]\n",
      " [2.0 2.0 7.0 ... 0.020202020202020204 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "0\n",
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[19.0 23.0 10.5 ... 0.0 0.0021929824561403508 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [30.0 107.0 3.1555555555555554 ... 0.000646830530401035 0.0 0.0]\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [16.0 27.0 7.75 ... 0.0054794520547945215 0.0027397260273972607 0.0]\n",
      " [2.0 6.0 2.3076923076923075 ... 0.003067484662576687 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.8052234109502832\n",
      "The test recall score is 0.3119834710743802\n",
      "The test precision score is 0.34553775743707094\n",
      "The test f1 score is 0.32790445168295335\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                               \"post\")\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, Y_train_bugs)\n",
    "DecisionTree(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [11.0 29.0 6.2857142857142865 ... 0.005747126436781609\n",
      "  0.0019157088122605363 0.0]\n",
      " ...\n",
      " [3.0 5.0 5.0 ... 0.0 0.0038910505836575885 0.0]\n",
      " [8.0 57.0 5.8235294117647065 ... 0.005285412262156447 0.0 0.0]\n",
      " [8.0 15.0 11.666666666666664 ... 0.0 0.0032679738562091504 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.8742290748898679\n",
      "The test recall score is 0.22069716775599124\n",
      "The test precision score is 0.7071353231691951\n",
      "The test f1 score is 0.33636912946972536\n"
     ]
    }
   ],
   "source": [
    "RandomForest(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2 Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.760981749528005\n",
      "The test recall score is 0.514410480349345\n",
      "The test precision score is 0.3058852129688798\n",
      "The test f1 score is 0.38302054377503314\n"
     ]
    }
   ],
   "source": [
    "neuralNetworks(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.2: Undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[16.0 28.0 6.0 ... 0.002053388090349076 0.002053388090349076 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [10.0 30.0 6.25 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [33.0 133.0 9.842105263157897 ... 0.013473053892215571\n",
      "  0.0007485029940119762 0.0]\n",
      " [17.0 65.0 6.9375 ... 0.009512485136741971 0.0011890606420927464 0.0]\n",
      " [4.0 7.0 3.25 ... 0.03424657534246575 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "160 160\n",
      "Y_resampled: [(False, 1079), (True, 1079)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                               \"post\")\n",
    "print(len(X_resampled[0]),len(X_test[0]))\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, Y_train_bugs)\n",
    "print(f'Y_resampled: {sorted(Counter(y_resampled).items())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled[0]),len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.4845814977973568\n",
      "The test recall score is 0.4703476482617587\n",
      "The test precision score is 0.14294592914853946\n",
      "The test f1 score is 0.21925643469971404\n"
     ]
    }
   ],
   "source": [
    "KNN(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.8470736312146003\n",
      "The test recall score is 0.14519427402862986\n",
      "The test precision score is 0.510791366906475\n",
      "The test f1 score is 0.22611464968152864\n"
     ]
    }
   ],
   "source": [
    "NaivceBayes(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.3080553807426054\n",
      "The test recall score is 0.6462167689161554\n",
      "The test precision score is 0.1349274124679761\n",
      "The test f1 score is 0.2232426704344755\n"
     ]
    }
   ],
   "source": [
    "logisticRegression(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[33.0 75.0 4.666666666666667 ... 0.002307692307692308 0.0 0.0]\n",
      " [3.0 9.0 4.6 ... 0.02008032128514056 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.04411764705882353 0.0 0.0]\n",
      " ...\n",
      " [10.0 10.0 8.0 ... 0.0 0.006211180124223602 0.0]\n",
      " [17.0 132.0 7.074074074074074 ... 0.0028517110266159697\n",
      "  0.0004752851711026616 0.0]\n",
      " [46.0 375.0 15.951219512195122 ... 0.012031826120706385\n",
      "  0.0001940617116242965 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.7995594713656387\n",
      "The test recall score is 0.35152838427947597\n",
      "The test precision score is 0.32135728542914166\n",
      "The test f1 score is 0.3357664233576642\n"
     ]
    }
   ],
   "source": [
    "DecisionTree(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.23826305852737567\n",
      "The test recall score is 0.6736196319018405\n",
      "The test precision score is 0.12715223135416193\n",
      "The test f1 score is 0.21392395201778186\n"
     ]
    }
   ],
   "source": [
    "RandomForest(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.4502202643171806\n",
      "The test recall score is 0.5222903885480572\n",
      "The test precision score is 0.14426972871420235\n",
      "The test f1 score is 0.22603565051422692\n"
     ]
    }
   ],
   "source": [
    "neuralNetworks(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2.3: Generate synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[6.0 15.0 4.0 ... 0.0045662100456621 0.0045662100456621 0.0]\n",
      " [34.0 190.0 15.173913043478262 ... 0.008047585724282715 0.0 0.0]\n",
      " [1.0 2.0 1.25 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [2.0 2.0 1.0 ... 0.08192090395480225 0.0 0.0]\n",
      " [22.0 83.0 11.727272727272727 ... 0.05233380480905234\n",
      "  0.0014144271570014145 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Y_resampled: [(False, 3399), (True, 5975)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_train,Y_train_bugs,X_test,Y_test_bugs = classification_binary(\"modified_eclipse-metrics-files-3.0.csv\",'FOUT_avg',\"NORM_SuperMethodInvocation\",0,\n",
    "                               \"post\")\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, Y_train_bugs)\n",
    "print(f'Y_resampled: {sorted(Counter(y_resampled).items())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.5701699181875394\n",
      "The test recall score is 0.7837209302325582\n",
      "The test precision score is 0.2093167701863354\n",
      "The test f1 score is 0.3303921568627451\n"
     ]
    }
   ],
   "source": [
    "KNN(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.8244178728760228\n",
      "The test recall score is 0.5069767441860467\n",
      "The test precision score is 0.3865248226950354\n",
      "The test f1 score is 0.4386317907444669\n"
     ]
    }
   ],
   "source": [
    "NaivceBayes(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.724669603524229\n",
      "The test recall score is 0.7255813953488373\n",
      "The test precision score is 0.29186155285313375\n",
      "The test f1 score is 0.41627751834556365\n"
     ]
    }
   ],
   "source": [
    "logisticRegression(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "AlltheMatrix/modified_eclipse-metrics-files-3.0.csv\n",
      "lens: 203\n",
      "start:6,end:167\n",
      "(10593,)\n",
      "the data shape is (10593, 160)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "[[12.0 29.0 10.666666666666666 ... 0.021645021645021644\n",
      "  0.004329004329004329 0.0]\n",
      " [25.0 134.0 14.818181818181818 ... 0.008888888888888889\n",
      "  0.0007407407407407407 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [10.0 41.0 3.7647058823529416 ... 0.005641748942172072 0.0 0.0]] (7415,)\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "The test accuracy score is 0.7920075519194462\n",
      "The test recall score is 0.31941544885177453\n",
      "The test precision score is 0.3135245901639344\n",
      "The test f1 score is 0.3164426059979317\n"
     ]
    }
   ],
   "source": [
    "DecisionTree(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.7675582127123978\n",
      "The test recall score is 0.6695348837209303\n",
      "The test precision score is 0.3255134082584211\n",
      "The test f1 score is 0.4380416799368483\n"
     ]
    }
   ],
   "source": [
    "RandomForest(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score is 0.6634361233480176\n",
      "The test recall score is 0.6897674418604651\n",
      "The test precision score is 0.2361646247041859\n",
      "The test f1 score is 0.3428917117554722\n"
     ]
    }
   ],
   "source": [
    "neuralNetworks(X_resampled,y_resampled,X_test,Y_test_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
